### Cours sur la Loi Normale

#### 1. Introduction √† la Loi Normale

La loi normale, √©galement appel√©e **loi de Gauss** en l'honneur de Carl Friedrich Gauss, est l'une des lois de probabilit√© les plus utilis√©es en statistiques et en probabilit√©s. 

>[!NOTE]
>Elle est particuli√®rement importante car de nombreux ph√©nom√®nes naturels ou sociaux suivent une distribution qui peut √™tre mod√©lis√©e par une loi normale.

La loi normale est une distribution continue, ce qui signifie qu'elle est utilis√©e pour des variables al√©atoires qui peuvent prendre une infinit√© de valeurs dans un intervalle donn√©.

>[!NOTES]
>Une variable al√©atoire est une fonction qui associe un nombre r√©el √† chaque issue d'une exp√©rience al√©atoire. 
>Par exemple, le lancer d'un d√© peut √™tre mod√©lis√© par une variable al√©atoire $ùëã$, $X$ prend la valeur 1, 2, 3, 4, 5 ou 6, selon le r√©sultat du lancer.

#### 2. Caract√©ristiques de la Loi Normale

<img src="../images/loi-normal.png" width="500" />

- **Sym√©trie** : La courbe de la loi normale est parfaitement sym√©trique par rapport √† sa moyenne. Cela signifie que la probabilit√© d'obtenir un r√©sultat plus grand ou plus petit que la moyenne est la m√™me.
  
- **Forme de la courbe** : La courbe de la loi normale est en forme de cloche. Elle est connue sous le nom de "courbe de Gauss". 

- **Param√®tres** : La loi normale est enti√®rement d√©finie par deux param√®tres :
  - **Moyenne ($ \mu$)** : Elle d√©finit le centre de la distribution.
  - **√âcart-type ($ \sigma$)** : Il d√©termine la dispersion de la distribution. Un petit √©cart-type signifie que les valeurs sont concentr√©es autour de la moyenne, tandis qu'un grand √©cart-type indique une plus grande dispersion.

  La notation g√©n√©rale d'une variable al√©atoire suivant une loi normale est :
  $X \sim N(\mu, \sigma^2)$
  o√π $ \mu$ est la moyenne et $ \sigma^2$ est la variance (l'√©cart-type est $ \sigma$).

#### 3. Fonction de Densit√© de Probabilit√©

La fonction de densit√© de probabilit√© (PDF) d'une loi normale est donn√©e par la formule :

$f(x) = \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(x - \mu)^2}{2\sigma^2}}$

Cette fonction d√©crit la probabilit√© de chaque valeur dans la distribution normale. Les √©l√©ments de la formule sont les suivants :
- $e$ est la base du logarithme naturel (environ 2,71828).
- $\pi$ est la constante math√©matique pi (environ 3,14159).
- $\mu$ est la moyenne.
- $\sigma$ est l'√©cart-type.

#### 4. Propri√©t√©s de la Loi Normale

- **Sym√©trie** : Comme mentionn√© plus haut, la loi normale est parfaitement sym√©trique par rapport √† sa moyenne $ \mu$.
- **Moyenne, M√©diane, Mode** : Dans une loi normale, la moyenne, la m√©diane et le mode sont tous √©gaux et se trouvent au m√™me endroit : au centre de la courbe.
- **Asymptotique** : La courbe de la loi normale s'√©tend √† l'infini dans les deux directions (vers $-\infty$ et $+\infty$), mais les probabilit√©s √† des valeurs extr√™mes deviennent n√©gligeables.
- **68-95-99.7 Rule** : Environ :
  - 68 % des valeurs se situent √† une distance de 1 √©cart-type de la moyenne ($\mu \pm \sigma$).
  - 95 % des valeurs se situent √† une distance de 2 √©carts-types de la moyenne ($\mu \pm 2\sigma$).
  - 99,7 % des valeurs se situent √† une distance de 3 √©carts-types de la moyenne ($\mu \pm 3\sigma$).

#### 5. Transformation et Standardisation

La transformation de variables suivant une loi normale est souvent effectu√©e √† l'aide de la **standardisation**. Cela permet de convertir une variable al√©atoire suivant une loi normale quelconque $ N(\mu, \sigma^2)$ en une variable suivant une loi normale standard $ N(0, 1)$.

La **standardisation** se fait par la transformation suivante :

$Z = \frac{X - \mu}{\sigma}$

Dans cette formule :
- $Z$ suit une loi normale standard $N(0,1)$ (moyenne 0 et √©cart-type 1).
- $X$ est une valeur observ√©e de la variable d'origine suivant la loi $N(\mu, \sigma^2)$.

Cela permet d'utiliser les tables de la loi normale standard pour obtenir des probabilit√©s et des quantiles.

#### 6. Calcul des Probabilit√©s

Les probabilit√©s associ√©es √† une variable al√©atoire suivant une loi normale peuvent √™tre calcul√©es √† l'aide de la fonction de distribution cumul√©e (CDF). Pour une loi normale standard, cette fonction est not√©e $ \Phi(z)$, o√π $ z$ est la variable standardis√©e.

Par exemple :
$P(X \leq x) = \Phi\left( \frac{x - \mu}{\sigma} \right)$

Pour des lois normales non standardis√©es, on effectue d'abord la transformation en $Z$ (comme expliqu√© pr√©c√©demment) avant de chercher la probabilit√© correspondante.

#### 7. Approximation de la Loi Normale

Dans certains cas, les distributions d'√©chantillons ou des variables al√©atoires peuvent ne pas √™tre directement normales, mais la loi normale peut servir d'approximation. Ce principe est √† la base du **Th√©or√®me Central Limite** (TCL), qui affirme que la somme de variables al√©atoires ind√©pendantes, quel que soit leur distribution initiale, tendra vers une loi normale lorsque le nombre de variables augmente.

>[!IMPORTANT]
>Le Th√©or√®me Central Limite (TCL) est utilis√© pour estimer la distribution d'une moyenne d'√©chantillons lorsqu'on pr√©l√®ve plusieurs √©chantillons d'une population, quelle que soit la distribution initiale. Lorsque la taille des √©chantillons est suffisamment grande (ùëõ ‚â• 30), la distribution des moyennes suit une loi normale. 
>
>**Cela permet de calculer des intervalles de confiance et de r√©aliser des tests d'hypoth√®ses pour la moyenne r√©elle.**

### TP Loi Normale

### **Exercice : Illustration du Th√©or√®me Central Limite avec Python**

Une entreprise souhaite analyser la moyenne des scores obtenus lors de lancers de d√©s pour diff√©rents groupes de joueurs. L'objectif est de comparer la variabilit√© des moyennes des scores entre des groupes de petite taille (5 joueurs) et des groupes plus grands (30 joueurs).

1. G√©n√©rer une **population** repr√©sentant les scores des lancers de d√©s (1 √† 6) pour 100 000 lancers.
2. Pr√©lever des √©chantillons de deux tailles diff√©rentes‚ÄØ:
   - Petits groupes : taille 5.
   - Grands groupes : taille 30.
3. Calculer les **moyennes** pour chaque groupe sur un total de 1 000 √©chantillons.
4. Visualiser les distributions des moyennes des √©chantillons.

---

### **√âtapes √† r√©aliser**

1. **G√©n√©rer la population :**
   - Simulez une population de 100 000 lancers de d√©s en utilisant une distribution uniforme entre 1 et 6.
   - Utilisez `numpy.random.randint` pour cr√©er cette population.

2. **Fonction de calcul des moyennes des √©chantillons :**
   - Impl√©mentez une fonction `sample_means` qui‚ÄØ:
     - Prend comme arguments‚ÄØ: la population, la taille des √©chantillons, et le nombre d'√©chantillons √† pr√©lever.
     - Retourne une liste contenant les moyennes de chaque √©chantillon.

3. **Calculer les moyennes :**
   - Utilisez la fonction `sample_means` pour :
     - Calculer 1 000 moyennes pour des √©chantillons de taille 5.
     - Calculer 1 000 moyennes pour des √©chantillons de taille 30.

4. **Visualiser les r√©sultats :**
   - Affichez deux histogrammes‚ÄØ:
     - Un pour les moyennes des petits √©chantillons.
     - Un pour les moyennes des grands √©chantillons.
   - Utilisez `matplotlib` ou `seaborn` pour tracer les histogrammes.

---

### **Crit√®res de validation**
1. Les distributions des moyennes pour $n=5$ et $n=30$ doivent √™tre affich√©es sur des histogrammes distincts.
2. Vous devez observer que‚ÄØ:
   - Les moyennes des petits √©chantillons ont une variabilit√© plus √©lev√©e (distribution plus large).
   - Les moyennes des grands √©chantillons sont concentr√©es autour de la moyenne r√©elle (distribution plus √©troite).

---

### **Indications**
- La fonction `np.random.choice` peut √™tre utile pour pr√©lever des √©chantillons dans la population.
- La visualisation peut √™tre am√©lior√©e avec `seaborn.histplot` pour une densit√© plus lisse.
- N‚Äôoubliez pas d‚Äôajouter des titres, labels et l√©gendes pour rendre vos graphiques lisibles.
- Utilisez ce code pour subdivier l'espace pour cr√©er deux histogramme c√¥te √† c√¥te `plt.subplot(1, 2, 1)` `plt.subplot(1, 2, 2)`
